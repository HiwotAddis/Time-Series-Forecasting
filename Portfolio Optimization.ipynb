{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485752a8",
   "metadata": {},
   "source": [
    "# Portfolio Optimization using MPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64f174",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# --- Parameters ---\n",
    "trading_days = 252\n",
    "n_portfolios = 20000   # Monte Carlo sample size; increase for smoother frontier\n",
    "risk_free_rate = 0.02  # annual risk-free rate used for Sharpe ratio (2%)\n",
    "\n",
    "# --- 0. Load return series for assets from your Task1 assets dict ---\n",
    "tsla = assets['TSLA']['Adj Close'].copy()\n",
    "bnd  = assets['BND']['Adj Close'].copy()\n",
    "spy  = assets['SPY']['Adj Close'].copy()\n",
    "\n",
    "# Align by date (inner join)\n",
    "prices = pd.concat([tsla, bnd, spy], axis=1, keys=['TSLA','BND','SPY'])\n",
    "prices.columns = prices.columns.droplevel(0)  # keep simple column names\n",
    "prices = prices.dropna()  # align to common trading days\n",
    "\n",
    "# Compute daily returns\n",
    "daily_returns = prices.pct_change().dropna()\n",
    "\n",
    "# --- 1. Expected returns vector ---\n",
    "# TSLA expected return from forecast if present\n",
    "def tsla_expected_return_from_forecast():\n",
    "    # try ARIMA then LSTM then combined\n",
    "    # expected return = annualized mean daily return of forecasted mean series (percentage change)\n",
    "    try:\n",
    "        # if combined DataFrame exists (Task3)\n",
    "        # combined should have 'LSTM_mean' or 'ARIMA_mean' columns\n",
    "        if 'combined' in globals():\n",
    "            # prefer the best-performing model — if unknown, pick ARIMA_mean if present\n",
    "            col = None\n",
    "            if 'ARIMA_mean' in combined.columns:\n",
    "                col = 'ARIMA_mean'\n",
    "            elif 'LSTM_mean' in combined.columns:\n",
    "                col = 'LSTM_mean'\n",
    "            if col:\n",
    "                fc = combined[col]\n",
    "                # compute daily returns of forecast (pct change)\n",
    "                fc_ret = fc.pct_change().dropna()\n",
    "                return fc_ret.mean() * trading_days  # annualize\n",
    "        # try arima_forecast_df\n",
    "        if 'arima_forecast_df' in globals():\n",
    "            fc = arima_forecast_df['mean']\n",
    "            fc_ret = fc.pct_change().dropna()\n",
    "            return fc_ret.mean() * trading_days\n",
    "        # try lstm_forecast_df\n",
    "        if 'lstm_forecast_df' in globals():\n",
    "            fc = lstm_forecast_df['mean']\n",
    "            fc_ret = fc.pct_change().dropna()\n",
    "            return fc_ret.mean() * trading_days\n",
    "    except Exception as e:\n",
    "        print(\"Forecast-based TSLA return extraction failed:\", e)\n",
    "    return None\n",
    "\n",
    "tsla_forecast_ann_return = tsla_expected_return_from_forecast()\n",
    "\n",
    "# If no forecast, fallback to historical annualized mean (use recent 1 year for forward-looking bias)\n",
    "if tsla_forecast_ann_return is None:\n",
    "    recent_days = 252  # last 1 year\n",
    "    tsla_hist = daily_returns['TSLA'].tail(recent_days)\n",
    "    tsla_forecast_ann_return = tsla_hist.mean() * trading_days\n",
    "    print(\"No forecast found — using recent historical annualized return for TSLA as proxy.\")\n",
    "\n",
    "# BND & SPY historical annualized mean returns (use full history)\n",
    "bnd_ann_return = daily_returns['BND'].mean() * trading_days\n",
    "spy_ann_return = daily_returns['SPY'].mean() * trading_days\n",
    "\n",
    "expected_returns = np.array([tsla_forecast_ann_return, bnd_ann_return, spy_ann_return])\n",
    "asset_names = ['TSLA', 'BND', 'SPY']\n",
    "\n",
    "# --- 2. Covariance matrix (annualized) ---\n",
    "cov_matrix_annual = daily_returns.cov() * trading_days\n",
    "cov_matrix_annual = cov_matrix_annual.loc[asset_names, asset_names].values\n",
    "\n",
    "# --- 3. Monte Carlo simulation to sample portfolios ---\n",
    "def portfolio_performance(weights, exp_rets, cov_matrix):\n",
    "    ret = np.dot(weights, exp_rets)\n",
    "    vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return ret, vol\n",
    "\n",
    "np.random.seed(42)\n",
    "results = np.zeros((n_portfolios, 3 + len(asset_names)))  # columns: ret, vol, sharpe, weights...\n",
    "for i in range(n_portfolios):\n",
    "    # random weights that sum to 1 (no shorting)\n",
    "    w = np.random.random(len(asset_names))\n",
    "    w /= np.sum(w)\n",
    "    ret, vol = portfolio_performance(w, expected_returns, cov_matrix_annual)\n",
    "    sharpe = (ret - risk_free_rate) / vol if vol > 0 else 0\n",
    "    results[i, 0] = ret\n",
    "    results[i, 1] = vol\n",
    "    results[i, 2] = sharpe\n",
    "    results[i, 3:] = w\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Return','Volatility','Sharpe'] + asset_names)\n",
    "\n",
    "# --- 4. Find Minimum Volatility portfolio from simulated set ---\n",
    "min_vol_idx = results_df['Volatility'].idxmin()\n",
    "min_vol_port = results_df.loc[min_vol_idx]\n",
    "\n",
    "# --- 5. Find Maximum Sharpe portfolio from simulated set ---\n",
    "max_sharpe_idx = results_df['Sharpe'].idxmax()\n",
    "max_sharpe_port = results_df.loc[max_sharpe_idx]\n",
    "\n",
    "# --- 6. Local optimization for more accurate Max Sharpe / Min Vol weights (constrained) ---\n",
    "# Constraints & bounds\n",
    "bounds = tuple((0,1) for _ in asset_names)  # no shorting\n",
    "cons = ({'type':'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "\n",
    "# Min volatility via scipy minimize\n",
    "def minimize_volatility(exp_rets, cov_matrix):\n",
    "    init_guess = np.array(len(asset_names)*[1/len(asset_names)])\n",
    "    def fun(w):\n",
    "        return np.sqrt(np.dot(w.T, np.dot(cov_matrix, w)))\n",
    "    res = minimize(fun, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "    return res.x\n",
    "\n",
    "minvol_weights = minimize_volatility(expected_returns, cov_matrix_annual)\n",
    "minvol_ret, minvol_vol = portfolio_performance(minvol_weights, expected_returns, cov_matrix_annual)\n",
    "minvol_sharpe = (minvol_ret - risk_free_rate) / minvol_vol\n",
    "\n",
    "# Max Sharpe via maximize Sharpe -> minimize negative Sharpe\n",
    "def maximize_sharpe(exp_rets, cov_matrix, rf):\n",
    "    init_guess = np.array(len(asset_names)*[1/len(asset_names)])\n",
    "    def neg_sharpe(w):\n",
    "        r, v = portfolio_performance(w, exp_rets, cov_matrix)\n",
    "        return - (r - rf) / v\n",
    "    res = minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "    return res.x\n",
    "\n",
    "maxsharpe_weights = maximize_sharpe(expected_returns, cov_matrix_annual, risk_free_rate)\n",
    "maxsharpe_ret, maxsharpe_vol = portfolio_performance(maxsharpe_weights, expected_returns, cov_matrix_annual)\n",
    "maxsharpe_sharpe = (maxsharpe_ret - risk_free_rate) / maxsharpe_vol\n",
    "\n",
    "# --- 7. Plot Efficient Frontier (simulated) and mark portfolios ---\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(results_df['Volatility'], results_df['Return'], c=results_df['Sharpe'], cmap='viridis', s=8, alpha=0.6)\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.scatter(minvol_vol, minvol_ret, marker='*', color='r', s=200, label='Min Vol (opt)')\n",
    "plt.scatter(maxsharpe_vol, maxsharpe_ret, marker='D', color='b', s=150, label='Max Sharpe (opt)')\n",
    "plt.xlabel('Annualized Volatility (Std Dev)')\n",
    "plt.ylabel('Annualized Return')\n",
    "plt.title('Efficient Frontier (Monte Carlo sample)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- 8. Results summary (print) ---\n",
    "def print_portfolio(name, weights, ret, vol, sharpe):\n",
    "    print(f\"--- {name} ---\")\n",
    "    for n, w in zip(asset_names, weights):\n",
    "        print(f\"{n}: {w:.4f}\")\n",
    "    print(f\"Expected Annual Return: {ret:.4%}\")\n",
    "    print(f\"Annual Volatility: {vol:.4%}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe:.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"From simulation (best found in simulated pool):\")\n",
    "print(\"Simulated Min Vol (approx):\")\n",
    "print(min_vol_port)\n",
    "print(\"Simulated Max Sharpe (approx):\")\n",
    "print(max_sharpe_port)\n",
    "print(\"\\nFrom local optimization (more precise):\")\n",
    "print_portfolio(\"Minimum Volatility (optimized)\", minvol_weights, minvol_ret, minvol_vol, minvol_sharpe)\n",
    "print_portfolio(\"Maximum Sharpe (optimized)\", maxsharpe_weights, maxsharpe_ret, maxsharpe_vol, maxsharpe_sharpe)\n",
    "\n",
    "# Return important objects for further reporting if needed\n",
    "optimization_results = {\n",
    "    'expected_returns': expected_returns,\n",
    "    'cov_matrix_annual': cov_matrix_annual,\n",
    "    'simulated_portfolios': results_df,\n",
    "    'minvol_optimized': {'weights': minvol_weights, 'ret': minvol_ret, 'vol': minvol_vol, 'sharpe': minvol_sharpe},\n",
    "    'maxsharpe_optimized': {'weights': maxsharpe_weights, 'ret': maxsharpe_ret, 'vol': maxsharpe_vol, 'sharpe': maxsharpe_sharpe}\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
